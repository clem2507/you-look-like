{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You look like notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdetr\\Documents\\GitHub\\you-look-like\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5  2022-5-3 torch 1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "WARNING: NMS time limit 0.130s exceeded\n",
      "Speed: 1.1ms pre-process, 16.4ms inference, 1.8ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You look like... Hilary Clinton\n"
     ]
    }
   ],
   "source": [
    "from yolov5.detect import run\n",
    "from util import resize_face\n",
    "from cnn.tf_cnn import predict\n",
    "\n",
    "out = run('weights/yolov5/best.pt', source=0, nosave=True, conf_thres=0.6)\n",
    "crop_im = resize_face(out['frame'], out['box'])\n",
    "\n",
    "\n",
    "cv2.imshow('cropped face', crop_im)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyWindow('cropped face')\n",
    "\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(crop_im)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_batch = img_batch/255\n",
    "\n",
    "softmax_pred = predict(img_batch)\n",
    "\n",
    "index = np.argmax(softmax_pred[0])\n",
    "\n",
    "file_content = open(\"celebrities_idx.txt\", \"r\").read()\n",
    "celebrities_index = file_content.split(\",\")\n",
    "\n",
    "print('You look like...', celebrities_index[index][2:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.tf_cnn import train\n",
    "\n",
    "train(batch=32, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import create_directories, build_search_url, download_extended_page, get_all_items\n",
    "\n",
    "# download celebrities pictures\n",
    "f = open('people.txt')\n",
    "keywords = f.read().splitlines()\n",
    "print(\"Number of keywords:\", len(keywords))\n",
    "\n",
    "sufix = \"face\"\n",
    "\n",
    "keywords = [keyword + \" \" + sufix for keyword in keywords]\n",
    "search_keywords = [str(item) for item in keywords]\n",
    "\n",
    "limit = 1400\n",
    "\n",
    "main_directory = \"data/cnn/download\"\n",
    "\n",
    "i_search_keywoard = 0\n",
    "\n",
    "while i_search_keywoard < len(search_keywords):\n",
    "\tsearch_term = search_keywords[i_search_keywoard]\n",
    "\n",
    "\tsubdirectory_name = search_term\n",
    "\tcreate_directories(main_directory, subdirectory_name)\n",
    "\n",
    "\turl = build_search_url(search_term)\n",
    "\traw_html = download_extended_page(url)\n",
    "\n",
    "\tget_all_items(raw_html, main_directory, subdirectory_name, limit)\n",
    "\n",
    "\ti_search_keywoard += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import is_face_centered\n",
    "\n",
    "# crop faces\n",
    "directory = 'data/cnn/download'\n",
    "save_directory = 'data/cnn/download_cropped'\n",
    "for celebrity in os.listdir(directory):\n",
    "    if not os.path.exists(f'{save_directory}/{celebrity}'):\n",
    "        os.mkdir(f'{save_directory}/{celebrity}')\n",
    "    for img in os.listdir(f'{directory}/{celebrity}'):\n",
    "        out = run('weights/yolov5/best.pt', source=f'{directory}/{celebrity}/{img}', nosave=True, conf_thres=0.8)\n",
    "        if out['num_pred'] == 1:\n",
    "            if is_face_centered(out['frame'], out['box']):\n",
    "                crop_im = resize_face(out['frame'], out['box'])\n",
    "                cv2.imwrite(f'{save_directory}/{celebrity}/{img}', crop_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment and balance data\n",
    "data_augmentor = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "]) \n",
    "\n",
    "directory = 'data/cnn/download_cropped'\n",
    "for celebrity in os.listdir(directory):\n",
    "    celebrity_images = os.listdir(f'{directory}/{celebrity}')\n",
    "    num_of_img = len(celebrity_images)\n",
    "    for i in range(500-num_of_img):\n",
    "        idx = random.randint(0, num_of_img-1)\n",
    "        img_path = f'{directory}/{celebrity}/{celebrity_images[idx]}'\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "        img = tf.cast(tf.expand_dims(img, 0), tf.float32)\n",
    "        aug_img = data_augmentor(img)\n",
    "        aug_img = np.reshape(aug_img.numpy(), (aug_img.shape[1], aug_img.shape[2], aug_img.shape[3]))\n",
    "        cv2.imwrite(f'{img_path[:-4]}_augmented_{i}.jpg', cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "822e501169b5cf6038b441d7dc7f0365e16bc999c384d919edb0bf942a8e9429"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
