{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\code\\you-look-like\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available ðŸ™‚\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    warnings.warn('CUDA is not available.')\n",
    "else:\n",
    "    print(\"CUDA is available ðŸ™‚\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CelebritiesDataset(Dataset):\n",
    "#     def __init__(self, path='./data/cnn/download_crop/', transform=transformations):\n",
    "#         super(CelebritiesDataset, self).__init__()\n",
    "#         self.data = datasets.ImageFolder(path,  transform)    # Create data from folder\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.data[idx]\n",
    "#         return x, y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12023\n",
      "8417 1803 1803\n"
     ]
    }
   ],
   "source": [
    "celebrities_dataset = datasets.ImageFolder(\"./data/cnn/download_crop/\",  transformations)\n",
    "\n",
    "length_test = int(len(celebrities_dataset) * 0.15)\n",
    "length_valid = int(len(celebrities_dataset) * 0.15)\n",
    "length_train = len(celebrities_dataset) - length_test - length_valid\n",
    "\n",
    "print(\"total\", len(celebrities_dataset))\n",
    "print(length_train, length_valid, length_test)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(celebrities_dataset, [length_train, length_valid, length_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameters we will use\n",
    "batch_size = 16\n",
    "learning_rate = 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\tdrop_last=True,\n",
    "\t\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\t\tnum_workers=4)\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\tdrop_last=True,\n",
    "\t\t\t\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\t\t\t\tnum_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\tdrop_last=True,\n",
    "\t\t\t\t\t\t\t\tshuffle=False,\n",
    "\t\t\t\t\t\t\t\tnum_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Celebrities(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Celebrities, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(100, 80, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(80)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(80, 50, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(50)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32*32*50, 100)\n",
    "        self.bn4 = nn.BatchNorm1d(100)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, 80)\n",
    "        self.bn5 = nn.BatchNorm1d(80)\n",
    "\n",
    "        self.fc3 = nn.Linear(80, 72)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        # x = x.reshape(x.size(0), 64*64*30)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn4(x)\n",
    "        # x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn5(x)\n",
    "        # x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celebrities(\n",
      "  (conv1): Conv2d(3, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(100, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(80, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=51200, out_features=100, bias=True)\n",
      "  (bn4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=100, out_features=80, bias=True)\n",
      "  (bn5): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=80, out_features=72, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Celebrities().to(device)\n",
    "# Print the structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in dataset:  8417\n",
      "Number of batches:  526\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of items in dataset: \", len(train_dataloader.dataset))\n",
    "print(\"Number of batches: \", len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.091, accuracy: 0.000 \n",
      "[   50/  526] train_loss: 4.181, accuracy: 12.000 \n",
      "[  100/  526] train_loss: 3.977, accuracy: 19.000 \n",
      "[  150/  526] train_loss: 3.736, accuracy: 6.000 \n",
      "[  200/  526] train_loss: 3.596, accuracy: 6.000 \n",
      "[  250/  526] train_loss: 3.533, accuracy: 19.000 \n",
      "[  300/  526] train_loss: 3.439, accuracy: 19.000 \n",
      "[  350/  526] train_loss: 3.340, accuracy: 31.000 \n",
      "[  400/  526] train_loss: 3.225, accuracy: 25.000 \n",
      "[  450/  526] train_loss: 3.166, accuracy: 38.000 \n",
      "[  500/  526] train_loss: 3.048, accuracy: 38.000 \n",
      "Train: epoch 0: train_loss=1842.520 running_loss=31.000\n",
      "Valid: epoch 0: valid_loss=337.280 running_loss=6.746\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.053, accuracy: 56.000 \n",
      "[   50/  526] train_loss: 2.684, accuracy: 12.000 \n",
      "[  100/  526] train_loss: 2.640, accuracy: 25.000 \n",
      "[  150/  526] train_loss: 2.632, accuracy: 25.000 \n",
      "[  200/  526] train_loss: 2.547, accuracy: 31.000 \n",
      "[  250/  526] train_loss: 2.487, accuracy: 38.000 \n",
      "[  300/  526] train_loss: 2.555, accuracy: 44.000 \n",
      "[  350/  526] train_loss: 2.514, accuracy: 50.000 \n",
      "[  400/  526] train_loss: 2.490, accuracy: 38.000 \n",
      "[  450/  526] train_loss: 2.426, accuracy: 62.000 \n",
      "[  500/  526] train_loss: 2.508, accuracy: 56.000 \n",
      "Train: epoch 1: train_loss=1337.979 running_loss=50.000\n",
      "Valid: epoch 1: valid_loss=287.318 running_loss=5.746\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.042, accuracy: 56.000 \n",
      "[   50/  526] train_loss: 1.742, accuracy: 88.000 \n",
      "[  100/  526] train_loss: 1.678, accuracy: 50.000 \n",
      "[  150/  526] train_loss: 1.672, accuracy: 75.000 \n",
      "[  200/  526] train_loss: 1.770, accuracy: 62.000 \n",
      "[  250/  526] train_loss: 1.687, accuracy: 50.000 \n",
      "[  300/  526] train_loss: 1.693, accuracy: 50.000 \n",
      "[  350/  526] train_loss: 1.693, accuracy: 50.000 \n",
      "[  400/  526] train_loss: 1.769, accuracy: 44.000 \n",
      "[  450/  526] train_loss: 1.785, accuracy: 81.000 \n",
      "[  500/  526] train_loss: 1.812, accuracy: 69.000 \n",
      "Train: epoch 2: train_loss=910.498 running_loss=56.000\n",
      "Valid: epoch 2: valid_loss=271.696 running_loss=5.434\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.021, accuracy: 75.000 \n",
      "[   50/  526] train_loss: 0.966, accuracy: 88.000 \n",
      "[  100/  526] train_loss: 0.859, accuracy: 94.000 \n",
      "[  150/  526] train_loss: 0.917, accuracy: 81.000 \n",
      "[  200/  526] train_loss: 0.888, accuracy: 94.000 \n",
      "[  250/  526] train_loss: 0.864, accuracy: 81.000 \n",
      "[  300/  526] train_loss: 0.946, accuracy: 94.000 \n",
      "[  350/  526] train_loss: 0.860, accuracy: 75.000 \n",
      "[  400/  526] train_loss: 0.950, accuracy: 75.000 \n",
      "[  450/  526] train_loss: 0.936, accuracy: 75.000 \n",
      "[  500/  526] train_loss: 0.865, accuracy: 69.000 \n",
      "Train: epoch 3: train_loss=475.217 running_loss=75.000\n",
      "Valid: epoch 3: valid_loss=268.643 running_loss=5.373\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.009, accuracy: 94.000 \n",
      "[   50/  526] train_loss: 0.367, accuracy: 94.000 \n",
      "[  100/  526] train_loss: 0.292, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.264, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.253, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.261, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.296, accuracy: 100.000 \n",
      "[  350/  526] train_loss: 0.252, accuracy: 100.000 \n",
      "[  400/  526] train_loss: 0.304, accuracy: 81.000 \n",
      "[  450/  526] train_loss: 0.340, accuracy: 94.000 \n",
      "[  500/  526] train_loss: 0.341, accuracy: 81.000 \n",
      "Train: epoch 4: train_loss=158.066 running_loss=81.000\n",
      "Valid: epoch 4: valid_loss=280.393 running_loss=5.608\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.001, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.125, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.111, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.104, accuracy: 94.000 \n",
      "[  200/  526] train_loss: 0.091, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.084, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.107, accuracy: 100.000 \n",
      "[  350/  526] train_loss: 0.093, accuracy: 94.000 \n",
      "[  400/  526] train_loss: 0.121, accuracy: 94.000 \n",
      "[  450/  526] train_loss: 0.108, accuracy: 94.000 \n",
      "[  500/  526] train_loss: 0.130, accuracy: 100.000 \n",
      "Train: epoch 5: train_loss=57.384 running_loss=100.000\n",
      "Valid: epoch 5: valid_loss=291.165 running_loss=5.823\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.001, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.053, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.033, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.036, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.066, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.056, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.036, accuracy: 100.000 \n",
      "[  350/  526] train_loss: 0.038, accuracy: 100.000 \n",
      "[  400/  526] train_loss: 0.033, accuracy: 100.000 \n",
      "[  450/  526] train_loss: 0.031, accuracy: 100.000 \n",
      "[  500/  526] train_loss: 0.096, accuracy: 100.000 \n",
      "Train: epoch 6: train_loss=25.555 running_loss=94.000\n",
      "Valid: epoch 6: valid_loss=290.152 running_loss=5.803\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.001, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.025, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.031, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.035, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.062, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.031, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.036, accuracy: 94.000 \n",
      "[  350/  526] train_loss: 0.021, accuracy: 100.000 \n",
      "[  400/  526] train_loss: 0.021, accuracy: 100.000 \n",
      "[  450/  526] train_loss: 0.052, accuracy: 100.000 \n",
      "[  500/  526] train_loss: 0.025, accuracy: 100.000 \n",
      "Train: epoch 7: train_loss=17.768 running_loss=100.000\n",
      "Valid: epoch 7: valid_loss=298.581 running_loss=5.972\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.000, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.013, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.026, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.021, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.021, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.020, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.016, accuracy: 100.000 \n",
      "[  350/  526] train_loss: 0.024, accuracy: 100.000 \n",
      "[  400/  526] train_loss: 0.043, accuracy: 100.000 \n",
      "[  450/  526] train_loss: 0.040, accuracy: 100.000 \n",
      "[  500/  526] train_loss: 0.017, accuracy: 100.000 \n",
      "Train: epoch 8: train_loss=13.580 running_loss=100.000\n",
      "Valid: epoch 8: valid_loss=314.369 running_loss=6.287\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.000, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.024, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.042, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.031, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.015, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.019, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.063, accuracy: 100.000 \n",
      "[  350/  526] train_loss: 0.050, accuracy: 94.000 \n",
      "[  400/  526] train_loss: 0.044, accuracy: 100.000 \n",
      "[  450/  526] train_loss: 0.068, accuracy: 100.000 \n",
      "[  500/  526] train_loss: 0.107, accuracy: 100.000 \n",
      "Train: epoch 9: train_loss=25.843 running_loss=94.000\n",
      "Valid: epoch 9: valid_loss=370.404 running_loss=7.408\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.003, accuracy: 100.000 \n",
      "[   50/  526] train_loss: 0.134, accuracy: 100.000 \n",
      "[  100/  526] train_loss: 0.193, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.270, accuracy: 94.000 \n",
      "[  200/  526] train_loss: 0.328, accuracy: 94.000 \n",
      "[  250/  526] train_loss: 0.344, accuracy: 88.000 \n",
      "[  300/  526] train_loss: 0.330, accuracy: 94.000 \n",
      "[  350/  526] train_loss: 0.361, accuracy: 69.000 \n",
      "[  400/  526] train_loss: 0.383, accuracy: 75.000 \n",
      "[  450/  526] train_loss: 0.329, accuracy: 94.000 \n",
      "[  500/  526] train_loss: 0.309, accuracy: 94.000 \n",
      "Train: epoch 10: train_loss=157.700 running_loss=81.000\n",
      "Valid: epoch 10: valid_loss=384.391 running_loss=7.688\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[    0/  526] train_loss: 0.006, accuracy: 94.000 \n",
      "[   50/  526] train_loss: 0.179, accuracy: 94.000 \n",
      "[  100/  526] train_loss: 0.119, accuracy: 100.000 \n",
      "[  150/  526] train_loss: 0.108, accuracy: 100.000 \n",
      "[  200/  526] train_loss: 0.110, accuracy: 100.000 \n",
      "[  250/  526] train_loss: 0.094, accuracy: 100.000 \n",
      "[  300/  526] train_loss: 0.120, accuracy: 94.000 \n",
      "[  350/  526] train_loss: 0.104, accuracy: 100.000 \n",
      "[  400/  526] train_loss: 0.098, accuracy: 100.000 \n",
      "[  450/  526] train_loss: 0.098, accuracy: 100.000 \n",
      "[  500/  526] train_loss: 0.097, accuracy: 88.000 \n",
      "Train: epoch 11: train_loss=59.298 running_loss=100.000\n",
      "Valid: epoch 11: valid_loss=362.713 running_loss=7.254\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\code\\you-look-like\\cnn.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/you-look-like/cnn.ipynb#ch0000013?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/you-look-like/cnn.ipynb#ch0000013?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/code/you-look-like/cnn.ipynb#ch0000013?line=8'>9</a>\u001b[0m     train_loss, running_loss \u001b[39m=\u001b[39m cnn\u001b[39m.\u001b[39;49mtrain_loop(model, train_dataloader, device, optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/you-look-like/cnn.ipynb#ch0000013?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain: epoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: train_loss=\u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m running_loss=\u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(e, train_loss, running_loss))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/you-look-like/cnn.ipynb#ch0000013?line=10'>11</a>\u001b[0m     train_loss, running_loss \u001b[39m=\u001b[39m cnn\u001b[39m.\u001b[39mvalid_loop(model, valid_dataloader, device, optimizer, criterion)\n",
      "File \u001b[1;32mc:\\code\\you-look-like\\cnn.py:16\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_dataloader, device, optimizer, criterion)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/code/you-look-like/cnn.py?line=12'>13</a>\u001b[0m size_dataset \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m     <a href='file:///c%3A/code/you-look-like/cnn.py?line=13'>14</a>\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataloader)\n\u001b[1;32m---> <a href='file:///c%3A/code/you-look-like/cnn.py?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_dataloader):\n\u001b[0;32m     <a href='file:///c%3A/code/you-look-like/cnn.py?line=16'>17</a>\u001b[0m     X \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='file:///c%3A/code/you-look-like/cnn.py?line=17'>18</a>\u001b[0m     y_true \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\code\\you-look-like\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\code\\you-look-like\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=313'>314</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\code\\you-look-like\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=919'>920</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=920'>921</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=921'>922</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=922'>923</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=923'>924</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=924'>925</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=925'>926</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m    <a href='file:///c%3A/code/you-look-like/venv/lib/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[1;32m--> <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=323'>324</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=325'>326</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/context.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/popen_spawn_win32.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/popen_spawn_win32.py?line=91'>92</a>\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/popen_spawn_win32.py?line=92'>93</a>\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/popen_spawn_win32.py?line=93'>94</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/popen_spawn_win32.py?line=94'>95</a>\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/reduction.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/reduction.py?line=58'>59</a>\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/louis/AppData/Local/Programs/Python/Python39/lib/multiprocessing/reduction.py?line=59'>60</a>\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(list(model.parameters()), lr=learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "valid_score_best = 0\n",
    "patience = 2\n",
    "num_epochs = 300\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "    train_loss, running_loss = cnn.train_loop(model, train_dataloader, device, optimizer, criterion)\n",
    "    print('Train: epoch {}: train_loss={:.3f} running_loss={:.3f}'.format(e, train_loss, running_loss))\n",
    "    train_loss, running_loss = cnn.valid_loop(model, valid_dataloader, device, optimizer, criterion)\n",
    "    print('Valid: epoch {}: valid_loss={:.3f} running_loss={:.3f}'.format(e, train_loss, running_loss))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # if valid_score > valid_score_best:\n",
    "    #     print('Best score: {}. Saving model...'.format(valid_score))\n",
    "    #     torch.save(model, 'model_params.pt')\n",
    "    #     valid_score_best = valid_score\n",
    "    # else:\n",
    "    #     patience -= 1\n",
    "    #     print('Score did not improve! {} <= {}. Patience left: {}'.format(valid_score,\n",
    "    #                                                                       valid_score_best,\n",
    "    #                                                                       patience))\n",
    "    # if patience == 0:\n",
    "    #     print('patience reduced to 0. Training Finished.')\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4683b20f8a9caa9df8f46d50d1d85dd41682cb3a42c762c3ccee7e06a2237664"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
