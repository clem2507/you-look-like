{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cdetr\\Documents\\GitHub\\you-look-like\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "from yolov5.detect import run\n",
    "from util import resize_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-5-3 torch 1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cdetr\\Documents\\GitHub\\you-look-like\\crop_images.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cdetr/Documents/GitHub/you-look-like/crop_images.ipynb#ch0000002?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m run(\u001b[39m'\u001b[39;49m\u001b[39myolov5/weights/best.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, source\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, nosave\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, conf_thres\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdetr/Documents/GitHub/you-look-like/crop_images.ipynb#ch0000002?line=1'>2</a>\u001b[0m crop_im \u001b[39m=\u001b[39m resize_face(out[\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m], out[\u001b[39m'\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cdetr/Documents/GitHub/you-look-like/crop_images.ipynb#ch0000002?line=3'>4</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m, crop_im)\n",
      "File \u001b[1;32mc:\\Users\\cdetr\\Documents\\GitHub\\you-look-like\\venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/venv/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/venv/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/venv/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/venv/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdetr\\Documents\\GitHub\\you-look-like\\yolov5\\detect.py:119\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(weights, source, data, imgsz, conf_thres, iou_thres, max_det, device, view_img, save_txt, save_conf, save_crop, nosave, classes, agnostic_nms, augment, visualize, update, project, name, exist_ok, line_thickness, hide_labels, hide_conf, half, dnn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/detect.py?line=116'>117</a>\u001b[0m selected_frame \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/detect.py?line=117'>118</a>\u001b[0m num_pred \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/detect.py?line=118'>119</a>\u001b[0m \u001b[39mfor\u001b[39;00m path, im, im0s, vid_cap, s \u001b[39min\u001b[39;00m dataset:\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/detect.py?line=119'>120</a>\u001b[0m     t1 \u001b[39m=\u001b[39m time_sync()\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/detect.py?line=120'>121</a>\u001b[0m     im \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(im)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\you-look-like\\yolov5\\utils\\datasets.py:383\u001b[0m, in \u001b[0;36mLoadStreams.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/utils/datasets.py?line=380'>381</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/utils/datasets.py?line=381'>382</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/utils/datasets.py?line=382'>383</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(x\u001b[39m.\u001b[39mis_alive() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreads) \u001b[39mor\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# q to quit\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/utils/datasets.py?line=383'>384</a>\u001b[0m         cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    <a href='file:///c%3A/Users/cdetr/Documents/GitHub/you-look-like/yolov5/utils/datasets.py?line=384'>385</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = run('yolov5/weights/best.pt', source=0, nosave=True, conf_thres=0.8)\n",
    "crop_im = resize_face(out['frame'], out['box'])\n",
    "\n",
    "cv2.imshow('image', crop_im)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/cnn/download'\n",
    "save_directory = 'data/cnn/download_cropped'\n",
    "for celebrity in os.listdir(directory):\n",
    "    if not os.path.exists(f'{save_directory}/{celebrity}'):\n",
    "        os.mkdir(f'{save_directory}/{celebrity}')\n",
    "    for img in os.listdir(f'{directory}/{celebrity}'):\n",
    "        out = run('yolov5/weights/best.pt', source=f'{directory}/{celebrity}/{img}', nosave=True, conf_thres=0.8)\n",
    "        if out['num_pred'] == 1:\n",
    "            crop_im = resize_face(out['frame'], out['box'])\n",
    "            cv2.imwrite(f'{save_directory}/{celebrity}/{img}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "822e501169b5cf6038b441d7dc7f0365e16bc999c384d919edb0bf942a8e9429"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
